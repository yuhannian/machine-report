import streamlit as st
import pandas as pd
from io import BytesIO, StringIO

# âœ… é…ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="åˆ†åˆ‡æœºå°æŸè€—æŠ¥è¡¨", layout="centered")
st.title("ğŸ“Š åˆ†åˆ‡æœºå°æ—¥æŸè€—æŠ¥è¡¨ç”Ÿæˆå™¨")

# âœ… è®¾ç½®æœ€ä½ç”Ÿäº§é‡é—¨æ§›
DAILY_PRODUCTION_MIN = 50

# âœ… åˆ¤æ–­æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦
def contains_chinese(text):
    return any('\u4e00' <= ch <= '\u9fff' for ch in text)

# âœ… åŒ…è£…ä¸Šä¼ æ–‡ä»¶ï¼Œæ¨¡æ‹Ÿé‡å‘½å
class RenamedUpload:
    def __init__(self, file_obj, new_name):
        self._file = file_obj
        self.name = new_name

    def getvalue(self):
        return self._file.getvalue()

# âœ… ç”ŸæˆæŠ¥è¡¨å‡½æ•°
def generate_machine_loss_report(df):
    grouped = df.groupby('åˆ†åˆ‡æœºå°')[['åŠ å·¥é‡', 'å®é™…æŸè€—']].sum().reset_index()
    grouped['æŸè€—ç‡'] = (grouped['å®é™…æŸè€—'] / grouped['åŠ å·¥é‡']).apply(lambda x: f"{x:.2%}")

    total_åŠ å·¥é‡ = grouped['åŠ å·¥é‡'].sum()
    total_å®é™…æŸè€— = grouped['å®é™…æŸè€—'].sum()
    total_æŸè€—ç‡ = f"{(total_å®é™…æŸè€— / total_åŠ å·¥é‡):.2%}"

    total_row = pd.DataFrame({
        'åˆ†åˆ‡æœºå°': ['åˆè®¡:'],
        'åŠ å·¥é‡': [round(total_åŠ å·¥é‡, 3)],
        'å®é™…æŸè€—': [round(total_å®é™…æŸè€—, 6)],
        'æŸè€—ç‡': [total_æŸè€—ç‡]
    })

    final_result = pd.concat([grouped, total_row], ignore_index=True)
    return final_result, total_åŠ å·¥é‡

# âœ… æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
uploaded_file = st.file_uploader("ğŸ“‚ è¯·ä¸Šä¼ å‘è´§æ•°æ® CSV æ–‡ä»¶ï¼ˆæ”¯æŒä¸­æ–‡å†…å®¹ï¼Œæ–‡ä»¶åå»ºè®®ä½¿ç”¨è‹±æ–‡ï¼‰", type="csv")

# âœ… ä¸Šä¼ åå¤„ç†é€»è¾‘
if uploaded_file:
    try:
        original_name = uploaded_file.name

        # å¦‚æœå«ä¸­æ–‡ï¼Œæ¨¡æ‹Ÿé‡å‘½å
        if contains_chinese(original_name):
            st.info(f"ğŸ“„ æ£€æµ‹åˆ°ä¸­æ–‡æ–‡ä»¶åï¼š{original_name}ï¼Œç³»ç»Ÿå·²è‡ªåŠ¨æ›¿æ¢ä¸º uploaded_file.csv å¤„ç†ã€‚")
            uploaded_file = RenamedUpload(uploaded_file, "uploaded_file.csv")

        # ä½¿ç”¨ getvalue è¯»å–å†…å®¹
        file_content = uploaded_file.getvalue().decode("utf-8-sig")
        df = pd.read_csv(StringIO(file_content))

        # éªŒè¯å¿…è¦åˆ—æ˜¯å¦å­˜åœ¨
        required_cols = {'åˆ†åˆ‡æœºå°', 'åŠ å·¥é‡', 'å®é™…æŸè€—'}
        if not required_cols.issubset(df.columns):
            st.error(f"âŒ ç¼ºå°‘å¿…è¦çš„åˆ—: {required_cols}")
        else:
            report_df, total_volume = generate_machine_loss_report(df)

            st.success(f"âœ… æ–‡ä»¶ `{uploaded_file.name}` è¯»å–æˆåŠŸï¼ŒæŠ¥è¡¨ç”Ÿæˆå¦‚ä¸‹ï¼š")
            st.dataframe(report_df, use_container_width=True)

            # åˆ¤æ–­æ˜¯å¦è¾¾æ ‡
            if total_volume < DAILY_PRODUCTION_MIN:
                st.error(f"âš ï¸ æ€»åŠ å·¥é‡ä¸º {total_volume:.2f} å¨ï¼Œä½äºæœ€ä½ç”Ÿäº§æ ‡å‡†ï¼ˆ{DAILY_PRODUCTION_MIN} å¨ï¼‰ï¼")
            else:
                st.success(f"âœ… æ€»åŠ å·¥é‡ä¸º {total_volume:.2f} å¨ï¼Œè¾¾åˆ°ç”Ÿäº§æ ‡å‡†ã€‚")

            # âœ… ä¸‹è½½æŠ¥è¡¨ä¸º Excel
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                report_df.to_excel(writer, index=False, sheet_name="åˆ†åˆ‡æœºå°æŸè€—")
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ Excel æŠ¥è¡¨",
                data=output.getvalue(),
                file_name="åˆ†åˆ‡æœºå°æŸè€—æŠ¥è¡¨.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

    except Exception as e:
        st.error(f"âŒ æ–‡ä»¶å¤„ç†å‡ºé”™ï¼š{e}")
